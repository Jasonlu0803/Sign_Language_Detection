{"cells":[{"cell_type":"code","execution_count":null,"id":"ixiMmbsc0Mbc","metadata":{"id":"ixiMmbsc0Mbc"},"outputs":[],"source":["!pip install mediapipe"]},{"cell_type":"markdown","id":"9eeee732","metadata":{"id":"9eeee732"},"source":["## 1. 前置套件與函式\n","將 Mediapipe 所偵測到的 Keypoints 繪製到空白圖像，經過標準化後儲存。keypoints 包含 pose, right_hand, lefthand"]},{"cell_type":"code","execution_count":null,"id":"895b91ba","metadata":{"id":"895b91ba"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import os\n","import numpy as np\n","\n","mp_holistic = mp.solutions.holistic # holistic model\n","mp_drawing = mp.solutions.drawing_utils # drawing utilities\n","\n","def mediapipe_detection(image, model): # 偵測動作\n","    '''make current frame writable, so that the Mediapipe holistic model can enter their detection value'''\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # color conversion\n","    image.flags.writeable = False                  # Image is no longer writeable\n","    results = model.process(image)                 # Make prediction\n","    image.flags.writeable = True                   # Image is now writeable\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # color conversion\n","    return image, results\n","\n","def draw_landmarks_and_styled_noface(image, results): # this function only draw dots on image but won't show it\n","    # draw face\n","    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n","                             # mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the dot\n","                              #mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) # color the line\n","                              #)\n","    # draw pose\n","    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n","                              mp_drawing.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=1),\n","                              mp_drawing.DrawingSpec(color=(80,44,121), thickness=1, circle_radius=1)\n","                              )\n","    # draw left hand\n","    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n","                              mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=1),\n","                              mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=1)\n","                              )\n","    # draw right hand\n","    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n","                              mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1),\n","                              mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=1)\n","                              )\n","\n","def extract_keypoints_1darray_noface(results): # 抓值\n","  '''\n","  pose: 33*4\n","  lh: 21*3\n","  rh: 21*3\n","  return: all value flattened into a 1d array\n","  '''\n","  pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n","  lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n","  rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n","  # all of the above will all be a 1d array due to the flatten()\n","  return np.concatenate([pose, lh, rh])\n","\n","def extract_keypoints_on_image_noface(results, resolution):\n","  blank_image = np.zeros((resolution, resolution, 3), dtype=np.float32) # all zero 2d array\n","  draw_landmarks_and_styled_noface(blank_image, results) # draw landmarks on blank image\n","  gray_image = cv2.cvtColor(blank_image, cv2.COLOR_RGB2GRAY)\n","  gray_image_std = gray_image/255.0 # Standardized\n","  return gray_image_std\n","\n","def is_keypoints_valid(results, action, single_hand_actions):\n","    # 單手動作和雙手動作的最小關鍵點數量標準\n","    min_single_hand_keypoints = 16 # 21\n","    min_double_hand_keypoints = 35 # 42\n","\n","    # 檢查手部關鍵點是否存在\n","    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros((21, 3))\n","    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros((21, 3))\n","\n","    # 計算關鍵點數量\n","    lh_count = np.count_nonzero(np.all(lh != 0, axis=1)) # 21\n","    rh_count = np.count_nonzero(np.all(rh != 0, axis=1)) # 21\n","\n","    # 根據動作類型判斷是否有效\n","    if action in single_hand_actions:\n","        # 單手動作至少一隻手達到最小關鍵點數量\n","        return lh_count >= min_single_hand_keypoints or rh_count >= min_single_hand_keypoints\n","    else:\n","        # 雙手動作兩隻手都要達到最小關鍵點數量\n","        return lh_count >= min_double_hand_keypoints and rh_count >= min_double_hand_keypoints"]},{"cell_type":"markdown","id":"6977aa40","metadata":{"id":"6977aa40"},"source":["## 2. 變數設置\n","一次以30為單位"]},{"cell_type":"code","execution_count":null,"id":"08e07b68","metadata":{"id":"08e07b68"},"outputs":[],"source":["# Path for exported data, numpy arrays\n","DATA_PATH_1d_nf = os.path.join('1Darray', 'MP_Data_1d_nf')\n","DATA_PATH_150_nf = os.path.join('image', 'MP_Data_Image_150_nf')\n","\n","# actions that we try to detect\n","actions = np.array(['apple', 'bad', 'eat', 'exercise', 'very', 'mood', 'then', 'plan to', 'you guys',\n","                    'we', 'suit to', 'good', 'tomorrow', 'weather', 'today'])\n","\n","single_hand_action = np.array(['you guys', 'weather', 'bad', 'very', 'good', 'apple', 'tomorrow'])\n","\n","# numbers of video\n","no_sequences = 30\n","\n","# How many frame in each video\n","sequence_length = 45"]},{"cell_type":"markdown","id":"738cc9e8","metadata":{"id":"738cc9e8"},"source":["## 3. 資料夾創建"]},{"cell_type":"code","execution_count":null,"id":"28ad1423","metadata":{"id":"28ad1423"},"outputs":[],"source":["# create folders\n","for action in actions:\n","    for sequence in range(no_sequences):\n","        try:                                                              # try create new folder\n","            os.makedirs(os.path.join(DATA_PATH_1d_nf, action, str(sequence)))\n","            os.makedirs(os.path.join(DATA_PATH_150_nf, action, str(sequence)))\n","        except:                                                           # if the folder exicts\n","            pass"]},{"cell_type":"markdown","id":"910462ab","metadata":{"id":"910462ab"},"source":["## 4. 開始抓取"]},{"cell_type":"code","execution_count":null,"id":"038eef7d","metadata":{"id":"038eef7d"},"outputs":[],"source":["# 改這兩行之前，資料夾要先創，請務必檢查\n","cur_action = 'bad' # 這邊改要錄的動作\n","start_from_here = 0 # 第幾個影片開始\n","sequence = start_from_here\n","is_sequence_invalid = False\n","\n","cap = cv2.VideoCapture(0) # grab the feed from device 0\n","# Set mediapipe model\n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: # 導入模型\n","    while sequence < no_sequences:\n","        for frame_num in range(sequence_length):\n","            # read feed\n","            ret, frame = cap.read() # grab current frame from webcam\n","\n","            # make detection\n","            image, results = mediapipe_detection(frame, holistic)\n","\n","            # draw landmarks\n","            draw_landmarks_and_styled_noface(image, results)\n","\n","            # apply wait logic:\n","            if frame_num == 0:\n","                cv2.putText(image, 'STARTING COLLECTION', (120, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n","                cv2.putText(image, 'Collecting frames for {} Videos Number {}'.format(cur_action, sequence), (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n","                cv2.imshow('OpenCV Feed', image)\n","                cv2.waitKey(2000)     # take 2 seconds break\n","            else:\n","                cv2.putText(image, 'Collecting frames for {} Videos Number {}'.format(cur_action, sequence), (15, 12),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n","                cv2.imshow('OpenCV Feed', image)\n","\n","            if not is_keypoints_valid(results, cur_action, single_hand_action):\n","                is_sequence_invalid = True\n","                cv2.putText(image, f'frame {frame_num} keypoints invalid'.format(cur_action, sequence), (15, 30),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n","                cv2.imshow('OpenCV Feed', image)\n","            else:\n","                # export keypoints\n","                # to 1darray no face\n","                keypoints = extract_keypoints_1darray_noface(results)\n","                npy_path = os.path.join(DATA_PATH_1d_nf, cur_action, str(sequence), str(frame_num))\n","                np.save(npy_path, keypoints)\n","\n","                # to image no face\n","                keypoints_image = extract_keypoints_on_image_noface(results, 150)\n","                image_path = os.path.join(DATA_PATH_150_nf, cur_action, str(sequence), str(frame_num))\n","                # cv2.imwrite(image_path + '.jpg', keypoints_image)\n","                np.save(image_path, keypoints_image)\n","\n","             # show to screen\n","            cv2.imshow('OpenCV Feed', image)\n","\n","            # break gracefully\n","            if cv2.waitKey(10) & 0xFF == ord('q'): # 跳下一部\n","                break\n","\n","        sequence += 1\n","\n","        if is_sequence_invalid:\n","            sequence -= 1\n","            is_sequence_invalid = False\n","            cv2.putText(image, 'keypoints lost, do it again'.format(cur_action, sequence), (850, 30),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 127, 0), 4, cv2.LINE_AA)\n","            cv2.imshow('OpenCV Feed', image)\n","            cv2.waitKey(1000)\n","\n","    cap.release() # release webcam\n","    cv2.destroyAllWindows() # close all windows\n","    cv2.waitKey(1) # make sure window close"]}],"metadata":{"colab":{"collapsed_sections":["N62VMC8mmnV9"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"}},"nbformat":4,"nbformat_minor":5}